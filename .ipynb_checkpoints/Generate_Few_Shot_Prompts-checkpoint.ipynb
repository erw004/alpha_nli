{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "20c9187f-4973-4a50-9487-13a00527ed5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import requests\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6f6fb6e9-b246-4ae2-8878-f99b15a2c9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"https://api.deepseek.com/chat/completions\"\n",
    "API_KEY = \"sk-0c126c7904e4462fa89549308e5de1e8\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "NSHOT = 2\n",
    "file_lock = threading.Lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec0e10b9-da1b-4365-b0af-7cbe93c8d246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_template(example):\n",
    "    formatted = []\n",
    "    formatted.append(\"Observation 1: \" + example['obs1'] + \"\\n\")\n",
    "    formatted.append(\"Observation 2: \" + example['obs2'] + \"\\n\")\n",
    "    formatted.append(\"Possible Explanations:\\n\")\n",
    "    formatted.append(\"1: \" + example['hyp1'] + \"\\n\")\n",
    "    formatted.append(\"2: \" + example['hyp2'] + \"\\n\")\n",
    "    formatted.append(\"Answer: \")\n",
    "    return \"\".join(formatted)\n",
    "\n",
    "def generate_few_shot_testcases(n): # for n shot\n",
    "    # Load JSONL data\n",
    "    x_train = []\n",
    "    with open(\"alphanli-train-dev/train.jsonl\") as f:\n",
    "        for line in f:\n",
    "            x_train.append(json.loads(line))\n",
    "\n",
    "    y_train = []\n",
    "    with open(\"alphanli-train-dev/train-labels.lst\") as f:\n",
    "        y_train = [int(line.strip()) for line in f]\n",
    "\n",
    "    x_val = []\n",
    "    with open(\"alphanli-train-dev/dev.jsonl\") as f:\n",
    "        for line in f:\n",
    "            x_val.append(json.loads(line))\n",
    "\n",
    "    y_val = []\n",
    "    with open(\"alphanli-train-dev/dev-labels.lst\") as f:\n",
    "        y_val = [int(line.strip()) for line in f]\n",
    "\n",
    "    prompts = []\n",
    "    for testcase in x_val:\n",
    "        prompt = []\n",
    "        indices = random.sample(range(len(x_train)), n)\n",
    "        for i in indices:\n",
    "            example = x_train[i]\n",
    "            label = y_train[i]\n",
    "            prompt.append(apply_template(example))\n",
    "            prompt.append(str(label) + \"\\n\\n\")\n",
    "        prompt.append(apply_template(testcase))\n",
    "        prompts.append(\"\".join(prompt))\n",
    "    return prompts, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "879760f7-d1a7-41e1-a8d5-0a7736b85a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_deepseek(prompt):\n",
    "    data = {\n",
    "        \"model\": \"deepseek-reasoner\",  # Use 'deepseek-reasoner' for R1 model or 'deepseek-chat' for V3 model\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI model that selects the most plausible explanation for a given pair of observations. Given two observations and multiple possible explanations, choose the explanation that best follows logically from the observations. Respond only with the correct answer number.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"temperature\": 0.5,\n",
    "        \"stream\": False  # Disable streaming\n",
    "    }\n",
    "    \n",
    "    response = requests.post(API_URL, headers=headers, json=data)\n",
    "    return response.json()\n",
    "\n",
    "def process_prompt(index, prompt):\n",
    "    result = query_deepseek(prompt)\n",
    "    \n",
    "    # Save to .jsonl immediately\n",
    "    with file_lock:\n",
    "        with open(\"deepseek_r1_results.jsonl\", \"a\") as f:\n",
    "            # Include metadata for retries\n",
    "            line = json.dumps({\n",
    "                \"index\": index,\n",
    "                \"response\": result,\n",
    "                \"success\": \"error\" not in result\n",
    "            })\n",
    "            f.write(line + \"\\n\")  # JSONL requires one JSON object per line\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bf719662-ce9d-4d3e-a7b0-c0955816cdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts, labels = generate_few_shot_testcases(NSHOT)\n",
    "for i, prompt in enumerate(prompts):\n",
    "    with open(\"prompts.jsonl\", \"a\") as f:\n",
    "        line = json.dumps({\n",
    "            \"index\": i,\n",
    "            \"prompt\": prompt,\n",
    "        })\n",
    "        f.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3de9ba-b756-4fa6-ac56-5f4b604e2b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|‚ñè                                                                                                                                            | 2/1532 [07:06<81:23:05, 191.49s/it]"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:\n",
    "    # Use executor.submit to pass multiple arguments\n",
    "    futures = [executor.submit(process_prompt, index, prompt) for index, prompt in enumerate(prompts)]\n",
    "    for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures)):\n",
    "        result = future.result()  # Wait for completion\n",
    "        results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8eb05243-7131-43b7-ba23-63dc4cae8a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [int(re.search(r\"\\d+\", result['choices'][0]['message']['content']).group()) for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "248ecf46-b70c-484f-8590-d93a1ca6a8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = sum(a == b for a, b in zip(predictions, labels)) / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "91401111-b029-40b4-99b0-7f4226e84b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1532\n"
     ]
    }
   ],
   "source": [
    "print(len(prompts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79779ca8-cb61-4962-8060-225cb3d0b313",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
