{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vm83di9rV3UP",
        "outputId": "8eae26dc-b7ce-4ffc-b724-e7f5f6ae7279"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.3.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHD0xTPOaLW8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import PreTrainedTokenizerFast, AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Tuple\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.optim import Optimizer, AdamW, Adam, SGD, RMSprop\n",
        "from tqdm.notebook import tqdm\n",
        "from transformers import AutoModelForSequenceClassification, RobertaForMultipleChoice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-u-qgHGR2MOJ"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class AlphaNLIExample:\n",
        "    choices: list[str]\n",
        "    label: int\n",
        "\n",
        "    @staticmethod\n",
        "    def from_dict(data: dict):\n",
        "      return AlphaNLIExample(\n",
        "        choices=data[\"choices\"],\n",
        "        label=data[\"label\"],\n",
        "      )\n",
        "\n",
        "\n",
        "def initialize_datasets(tokenizer: PreTrainedTokenizerFast, sample: bool, data_file: str, label_data: str, sample_size: int = 0) -> dict:\n",
        "    # load dataset\n",
        "    raw_data = load_dataset(\"json\", data_files=data_file)\n",
        "\n",
        "    labels = list()\n",
        "    if label_data != \"N/A\":\n",
        "      # read labels\n",
        "      with open(label_data, \"r\") as f:\n",
        "        labels = [int(line.strip())-1 for line in f]\n",
        "    else:\n",
        "      # for test data since it doesn't come with labels\n",
        "      print(len(raw_data[\"train\"]))\n",
        "      labels = [1 for line in len(raw_data[\"train\"])]\n",
        "\n",
        "    # add labels to dataset\n",
        "    raw_data[\"train\"] = raw_data[\"train\"].add_column(\"label\", labels)\n",
        "\n",
        "    # generate our choices (based on linear chain: obs1 -> hyp -> obs2)\n",
        "    raw_data[\"train\"] = raw_data[\"train\"].add_column(\"choices\", [[x[\"obs1\"] + \" \" + x[\"hyp1\"] + \" \" + x[\"obs2\"],\n",
        "                                                                x[\"obs1\"] + \" \" + x[\"hyp2\"] + \" \" + x[\"obs2\"]] for x in raw_data[\"train\"]])\n",
        "\n",
        "    # just for now - take random sampling of 1000\n",
        "    #dataset = raw_data\n",
        "    dataset = {\n",
        "        \"train\": raw_data[\"train\"].shuffle(seed=42).select(range(sample_size)) if sample else raw_data[\"train\"]\n",
        "    }\n",
        "\n",
        "    # initialize as AlphaNLI Dataset\n",
        "    split_datasets = {}\n",
        "    for split_name in dataset.keys():\n",
        "      split_data = list(dataset[split_name])\n",
        "      split_datasets[split_name] = AlphaNLIDataset(tokenizer, split_data)\n",
        "\n",
        "    return split_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmVjzxII_0JM"
      },
      "outputs": [],
      "source": [
        "class AlphaNLIDataset(Dataset):\n",
        "    tokenizer: PreTrainedTokenizerFast = None\n",
        "\n",
        "    def __init__(self, tokenizer: PreTrainedTokenizerFast, raw_data_list: List[dict]):\n",
        "        AlphaNLIDataset.tokenizer = tokenizer\n",
        "        self.sample_list = [AlphaNLIExample.from_dict(data) for data in raw_data_list]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sample_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.sample_list[idx]\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(self.sample_list)\n",
        "\n",
        "    @staticmethod\n",
        "    def collate_fn(batched_samples: List[AlphaNLIExample]) -> dict:\n",
        "        batched_choices = [sample.choices for sample in batched_samples]\n",
        "        batched_label = [sample.label for sample in batched_samples]\n",
        "\n",
        "        # choice_encoding = AlphaNLIDataset.tokenizer(batched_choices,\n",
        "        #                                       padding=True,\n",
        "        #                                       max_length=512,\n",
        "        #                                       truncation=True,\n",
        "        #                                       return_tensors=\"pt\")\n",
        "        tokenized_choices = []\n",
        "        for choices in batched_choices:\n",
        "            # Tokenize each choice in the pair\n",
        "            tokenized_pair = AlphaNLIDataset.tokenizer(\n",
        "                choices,  # List of strings (e.g., [\"obs1 hyp1 obs2\", \"obs1 hyp2 obs2\"])\n",
        "                padding=\"max_length\",\n",
        "                truncation=True,\n",
        "                max_length=256,\n",
        "                return_tensors=\"pt\",\n",
        "            )\n",
        "            tokenized_choices.append(tokenized_pair)\n",
        "\n",
        "        # Stack tokenized inputs into the correct shape\n",
        "        input_ids = torch.stack([tc[\"input_ids\"] for tc in tokenized_choices])  # (batch_size, num_choices, seq_len)\n",
        "        attention_mask = torch.stack([tc[\"attention_mask\"] for tc in tokenized_choices])\n",
        "\n",
        "        label_encoding = torch.LongTensor(batched_label)\n",
        "\n",
        "        return {'input_ids': input_ids, 'attention_mask': attention_mask, 'label': label_encoding}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Vd-G-oUDL5P"
      },
      "outputs": [],
      "source": [
        "# this is like ALL AI - so should change this up a little\n",
        "\n",
        "def train_one_epoch(\n",
        "    model: nn.Module,\n",
        "    dataloader: DataLoader,\n",
        "    optimizer: Optimizer,\n",
        "    epoch: int,\n",
        "    gradient_accumulation_steps: int = 4,  # Number of steps to accumulate gradients\n",
        "    target_batch_size: int = 32,  # Simulated larger batch size\n",
        "):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    effective_batch_size = target_batch_size\n",
        "    actual_batch_size = dataloader.batch_size\n",
        "    assert effective_batch_size % actual_batch_size == 0, (\n",
        "        f\"Target batch size ({effective_batch_size}) must be divisible by \"\n",
        "        f\"actual batch size ({actual_batch_size}).\"\n",
        "    )\n",
        "    gradient_accumulation_steps = effective_batch_size // actual_batch_size\n",
        "\n",
        "    with tqdm(dataloader, desc=f\"Train Ep {epoch}\", total=len(dataloader)) as tq:\n",
        "        for step, batch in enumerate(tq):\n",
        "            input_ids = batch['input_ids'].to(model.device)\n",
        "            attention_mask = batch['attention_mask'].to(model.device)\n",
        "            label_encoding = batch['label'].to(model.device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=label_encoding)\n",
        "            loss = outputs.loss / gradient_accumulation_steps  # Scale loss by accumulation steps\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            # Perform optimizer step and zero gradients after accumulating enough steps\n",
        "            if (step + 1) % gradient_accumulation_steps == 0:\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            # Update progress bar\n",
        "            tq.set_postfix({\"loss\": loss.detach().item() * gradient_accumulation_steps})  # Rescale loss for display\n",
        "\n",
        "        # Handle the last batch if it doesn't align with gradient_accumulation_steps\n",
        "        if (step + 1) % gradient_accumulation_steps != 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQFeSNL_dgv9"
      },
      "outputs": [],
      "source": [
        "def evaluate(model: nn.Module, dataloader: DataLoader, testing: bool) -> float:\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    with tqdm(dataloader, desc=f\"Eval\", total=len(dataloader)) as tq:\n",
        "        for batch in tq:\n",
        "            with torch.no_grad():\n",
        "                input_ids = batch['input_ids'].to(model.device)\n",
        "                attention_mask = batch['attention_mask'].to(model.device)\n",
        "                label_encoding = batch['label'].to(model.device)\n",
        "\n",
        "                outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=label_encoding)\n",
        "                logits = outputs.logits\n",
        "\n",
        "                predictions = torch.argmax(logits, dim=-1)\n",
        "                labels = label_encoding\n",
        "\n",
        "                all_predictions += predictions\n",
        "                all_labels += labels\n",
        "\n",
        "    all_predictions = torch.Tensor(all_predictions)\n",
        "    all_labels = torch.Tensor(all_labels)\n",
        "    accuracy = compute_accuracy(all_predictions, all_labels)\n",
        "\n",
        "    if testing:\n",
        "        with open(\"anli.lst\", \"w\") as f:\n",
        "            for pred in all_predictions:\n",
        "                f.write(f\"{pred}\\n\")\n",
        "            print(len(f))\n",
        "\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "def compute_accuracy(predictions: torch.Tensor, labels: torch.Tensor) -> float:\n",
        "    assert predictions.size(-1) == labels.size(-1)\n",
        "    accuracy = (predictions == labels).sum().item() / len(labels)\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WA6sf-J3PUTt"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(64)\n",
        "\n",
        "def main(batch_size, learning_rate, num_epochs, grad_accum):\n",
        "    model_name = \"roberta-base\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = RobertaForMultipleChoice.from_pretrained(model_name)\n",
        "    model = model.cuda()\n",
        "    optimizer = AdamW(model.parameters(), lr=learning_rate, eps=1e-8)\n",
        "\n",
        "    datasets = initialize_datasets(tokenizer, sample=True, data_file=\"train.jsonl\", label_data=\"train-labels.lst\", sample_size=1000)\n",
        "    print(datasets['train'][0])\n",
        "\n",
        "    train_dataloader = DataLoader(datasets['train'],\n",
        "                                   batch_size=batch_size,\n",
        "                                   shuffle=True,\n",
        "                                   collate_fn=AlphaNLIDataset.collate_fn,\n",
        "                                   num_workers=2)\n",
        "\n",
        "    dev_datasets = initialize_datasets(tokenizer, sample=False, data_file=\"dev.jsonl\", label_data=\"dev-labels.lst\")\n",
        "    dev_dataloader = DataLoader(dev_datasets['train'],\n",
        "                                   batch_size=batch_size,\n",
        "                                   shuffle=True,\n",
        "                                   collate_fn=AlphaNLIDataset.collate_fn,\n",
        "                                   num_workers=2)\n",
        "\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        train_one_epoch(model, train_dataloader, optimizer, epoch, gradient_accumulation_steps=grad_accum, target_batch_size=batch_size)\n",
        "        valid_acc = evaluate(model, dev_dataloader, testing=False)\n",
        "        if valid_acc > best_acc:\n",
        "            best_acc = valid_acc\n",
        "            torch.save(model.state_dict(), 'best_model.pt')\n",
        "    return best_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "aa3904cdd327406782555f924bd3769d",
            "9758435177264cae9ad9e40d32240077",
            "da38b7f2188b43f0acf5b4667002f33a",
            "c0be4c68edb242f68927ffdf1fd73139",
            "3a73a783c8d3497dbbd87bec1cd2db31",
            "f3533127578f4d52a6644886307c0946",
            "67ac579c45104f2e950e8928273aec8b",
            "a2b8e1476d8641c4ac323f8044d6d62f",
            "add9fabcb92a4622a92c5cb675eb9dcc",
            "a99fe2440e744aacbdc3c8544b0d4a19",
            "c35d90edb234408c9b19c22708de27fe",
            "e129406d15894e639dddf4ab365adc66",
            "60cccb9cd36446a8a2699efba102e812",
            "ddc1bb87990245b69268121e59b263c8",
            "42a6c11641054fe0a19894fbd7dd974e",
            "03376f2850214d51ac29ef8d7bd5e586"
          ]
        },
        "id": "S-pq8abyPt0L",
        "outputId": "bdd05e97-b93f-41de-b67d-c851f19770e1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForMultipleChoice were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AlphaNLIExample(choices=['Albert was a weight loss guru. Albert increased his exercise regimen. He died of a heart attack on the last mile.', 'Albert was a weight loss guru. Albert stopped his exercise regimen. He died of a heart attack on the last mile.'], label=0)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa3904cdd327406782555f924bd3769d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train Ep 1:   0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e129406d15894e639dddf4ab365adc66",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Eval:   0%|          | 0/48 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5672323759791122\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60cccb9cd36446a8a2699efba102e812",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train Ep 2:   0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ddc1bb87990245b69268121e59b263c8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Eval:   0%|          | 0/48 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5900783289817232\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42a6c11641054fe0a19894fbd7dd974e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train Ep 3:   0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03376f2850214d51ac29ef8d7bd5e586",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Eval:   0%|          | 0/48 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5926892950391645\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.5926892950391645"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "main(batch_size=32, learning_rate=5e-5, num_epochs=3, grad_accum=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWguh0dZ9aQa"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
        "\n",
        "model = RobertaForMultipleChoice.from_pretrained(\"roberta-base\")\n",
        "model.load_state_dict(torch.load('best_model.pt'))\n",
        "model = model.cuda()\n",
        "\n",
        "datasets = initialize_datasets(tokenizer, sample=False, data_file=\"anli.jsonl\", label_data=\"N/A\")\n",
        "test_dataloader = DataLoader(datasets['train'],\n",
        "                                   batch_size=64,\n",
        "                                   shuffle=False,\n",
        "                                   collate_fn=AlphaNLIDataset.collate_fn,\n",
        "                                   num_workers=2)\n",
        "\n",
        "# should create new file anli.lst that has all test labels\n",
        "evaluate(model, test_dataloader, testing=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3a73a783c8d3497dbbd87bec1cd2db31": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67ac579c45104f2e950e8928273aec8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9758435177264cae9ad9e40d32240077": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3533127578f4d52a6644886307c0946",
            "placeholder": "​",
            "style": "IPY_MODEL_67ac579c45104f2e950e8928273aec8b",
            "value": "Train Ep 1:   0%"
          }
        },
        "a2b8e1476d8641c4ac323f8044d6d62f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a99fe2440e744aacbdc3c8544b0d4a19": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa3904cdd327406782555f924bd3769d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9758435177264cae9ad9e40d32240077",
              "IPY_MODEL_da38b7f2188b43f0acf5b4667002f33a",
              "IPY_MODEL_c0be4c68edb242f68927ffdf1fd73139"
            ],
            "layout": "IPY_MODEL_3a73a783c8d3497dbbd87bec1cd2db31"
          }
        },
        "add9fabcb92a4622a92c5cb675eb9dcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c0be4c68edb242f68927ffdf1fd73139": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a99fe2440e744aacbdc3c8544b0d4a19",
            "placeholder": "​",
            "style": "IPY_MODEL_c35d90edb234408c9b19c22708de27fe",
            "value": " 0/32 [00:00&lt;?, ?it/s]"
          }
        },
        "c35d90edb234408c9b19c22708de27fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da38b7f2188b43f0acf5b4667002f33a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2b8e1476d8641c4ac323f8044d6d62f",
            "max": 32,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_add9fabcb92a4622a92c5cb675eb9dcc",
            "value": 0
          }
        },
        "f3533127578f4d52a6644886307c0946": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
